#!/usr/bin/env python
# -*- coding: utf-8 -*-

import configparser
import logging
from bs4 import BeautifulSoup  # Updated import
from Helpers import Download, Parser, helpers

class ClassName(object):
    def __init__(self, domain, verbose=False):
        self.apikey = False
        self.name = "Searching Canary Paste Bin"
        self.description = "Search Canary for paste potential data dumps, this can take a bit but a great source"
        self.domain = domain
        self.Html = ""
        self.verbose = verbose
        self.UserAgent = {'User-Agent': helpers.get_user_agent()}
        self.logger = logging.getLogger("SimplyEmail.AskSearch")

        config = configparser.ConfigParser()
        config.read('Common/SimplyEmail.ini')

        try:
            self.Depth = int(config['CanaryPasteBin']['PageDepth'])
            self.Counter = int(config['CanaryPasteBin']['QueryStart'])
        except KeyError as e:
            self.logger.critical(f'CanaryBinSearch module failed to load: {e}')
            print(helpers.color("[*] Major Settings for Canary PasteBin Search are missing, EXITING!\n", warning=True))

    def execute(self):
        self.logger.debug("CanaryBinSearch module started")
        self.process()
        return self.get_emails()

    def process(self):
        url_list = []
        dl = Download.Download(verbose=self.verbose)

        while self.Counter <= self.Depth:
            if self.verbose:
                p = f' [*] Canary Search on page: {self.Counter}'
                self.logger.info(f"CanaryBinSearch on page: {self.Counter}")
                print(helpers.color(p, firewall=True))

            try:
                url = f"https://canary.pw/search/?q={self.domain}&page={self.Counter}"
                rawhtml, statuscode = dl.requesturl(url, useragent=self.UserAgent, statuscode=True, verify=False)
                if statuscode != 200:
                    break
            except Exception as e:
                error = f" [!] Major issue with Canary Pastebin Search: {e}"
                self.logger.error(f'Fail during Request to CanaryBinSearch (Check Connection): {e}')
                print(helpers.color(error, warning=True))

            soup = BeautifulSoup(rawhtml, 'html.parser')
            for a in soup.find_all('a', href=True):
                if a['href'].startswith('/view'):
                    url_list.append(a['href'])
            self.Counter += 1

        status = f" [*] Canary found {len(url_list)} CanaryBin(s) to Search!"
        self.logger.info(f"CanaryBin found {len(url_list)} CanaryBin(s) to Search!")
        print(helpers.color(status, status=True))

        for item in url_list:
            try:
                item_url = f"https://canary.pw{item}"
                rawhtml = dl.requesturl(item_url, useragent=self.UserAgent, timeout=20)
                self.Html += rawhtml
            except Exception as e:
                error = f" [!] Connection Timed out on Canary Pastebin Search: {e}"
                self.logger.error(f'Fail during Request to CanaryBinSearch bin (Check Connection): {e}')
                print(helpers.color(error, warning=True))

    def get_emails(self):
        parser = Parser.Parser(self.Html)
        parser.generic_clean()
        parser.url_clean()
        final_output = parser.grep_find_emails()
        html_results = parser.build_results(final_output, self.name)
        json_results = parser.build_json(final_output, self.name)
        self.logger.debug('CanaryBinSearch completed search')
        return final_output, html_results, json_results
